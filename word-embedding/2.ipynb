{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Mechanism\n",
    "# how one word in a sequence is related to other\n",
    "# ex : cat sit ion the mat\n",
    "# word embedding  --->  understnad menaing\n",
    "# text to int conversion (ml) - NLP (Nartural Lang Proceing)\n",
    "# 3 mainthod to (text to int conversion)   -  word embedding ,  one-hot hot,  interter encondin\n",
    "# one hot encoding  - ex: cat sit ion the mat\n",
    " #  create a unique words of thedata [ cat,  sit , on, the, mat]\n",
    " # create a sperse vector for each vocab  cat [1,0,0,0,0] , sit [0,1,0,0,0]\n",
    " #diasvdatge - cannt unsetand the semantic / content ,  large spare vector\n",
    "\n",
    "# inter encoding - [ 1,  2 ,3, 4, 5] ,  dense vector, most compact ,  no context, semantic\n",
    "\n",
    "# word embdding - have trainable paremeter (vectors) -   embeddinglayer(5, 2)\n",
    "# cat [0.1, 0.5],  sit [[0.1, 0.5]] , on [0.1, 0.5], the [0.1, 0.5], mat[0.1, 0.5]\n",
    "# train model : \n",
    "# its create a vector space for all the vocabulary\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'urls_pos.txt', 'urls_neg.txt', 'pos', 'labeledBow.feat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word embdding\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# prepare data\n",
    "train_dir = os.path.join(\"aclImdb_v1_extracted/aclImdb/test\")\n",
    "\n",
    "os.listdir(train_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.text_dataset_from_directory(train_dir , validation_split=0.2, subset=\"training\" ,batch_size=32 ,seed=42)\n",
    "valid_ds = tf.keras.utils.text_dataset_from_directory(train_dir, validation_split=0.2, subset=\"validation\", batch_size=32, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
       "array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ , label = next(iter(train_ds))\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is cache and prefetch ?  chcek - small to medium , that can fit inside you computer ram or harddisk\n",
    "# confihure datset for performance , prefetch - one batch is training in gpus, other prepare and setup in cpu , AUTOTUNE?\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size = AUTOTUNE)\n",
    "\n",
    "valid_ds = valid_ds.cache().prefetch(buffer_size=  AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 2), dtype=float32, numpy=\n",
       "array([[ 0.00576295,  0.01189106],\n",
       "       [ 0.04488179,  0.02726892],\n",
       "       [-0.03844514, -0.02120103],\n",
       "       [ 0.00848771,  0.0305177 ],\n",
       "       [-0.03398626, -0.0248061 ],\n",
       "       [-0.03844514, -0.02120103]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model  = nn.Suwnetion([embedding,  dense])\n",
    "emdeb_layer = tf.keras.layers.Embedding(5, 2) \n",
    "\n",
    "a = tf.constant([1, 2, 3, 4, 0, 3 ]) # shape(3,)\n",
    "\n",
    "emdeb_layer(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "def standardizer(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(stripped_html,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_layer = tf.keras.layers.TextVectorization(standardize = standardizer,\n",
    "                                                      max_tokens = 10000,\n",
    "                                                      output_sequence_length = 100,\n",
    "                                                      output_mode='int',\n",
    "\n",
    "                                                      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-24 16:07:32.733973: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "text_ds = train_ds.map(lambda x, y : x)\n",
    "\n",
    "vectorized_layer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.str_('any')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_layer.get_vocabulary()[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 8\n",
    "model = tf.keras.Sequential([\n",
    "    vectorized_layer,\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),  # 32,100,8\n",
    "    tf.keras.layers.GlobalAveragePooling1D(), #32,8\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "model.compile(loss=loss_fn, optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5282 - loss: 0.6641 - val_accuracy: 0.7860 - val_loss: 0.4590\n",
      "Epoch 2/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7936 - loss: 0.4207 - val_accuracy: 0.8342 - val_loss: 0.3688\n",
      "Epoch 3/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8599 - loss: 0.3185 - val_accuracy: 0.8442 - val_loss: 0.3541\n",
      "Epoch 4/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8874 - loss: 0.2676 - val_accuracy: 0.8480 - val_loss: 0.3567\n",
      "Epoch 5/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2341 - val_accuracy: 0.8428 - val_loss: 0.3718\n",
      "Epoch 6/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2103 - val_accuracy: 0.8428 - val_loss: 0.3906\n",
      "Epoch 7/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9310 - loss: 0.1859 - val_accuracy: 0.8364 - val_loss: 0.4123\n",
      "Epoch 8/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9408 - loss: 0.1665 - val_accuracy: 0.8372 - val_loss: 0.4384\n",
      "Epoch 9/50\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9479 - loss: 0.1486 - val_accuracy: 0.8334 - val_loss: 0.4718\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x145147ed0>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard_callbacks = [tf.keras.callbacks.TensorBoard(log_dir=\"my_logs\"),\n",
    "                         tf.keras.callbacks.EarlyStopping(patience=6,  monitor='val_loss')\n",
    "                         ]\n",
    "\n",
    "model.fit(train_ds, validation_data=valid_ds , epochs=50 , callbacks=tensorboard_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 3970), started 0:01:01 ago. (Use '!kill 3970' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2600662f20e83519\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2600662f20e83519\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir my_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.0148323 ,  0.00039671, -0.00739485, ...,  0.01767139,\n",
       "         -0.02954   ,  0.00295945],\n",
       "        [-0.01629905, -0.04476994,  0.01218414, ...,  0.03683555,\n",
       "         -0.01622739, -0.01802848],\n",
       "        [ 0.02233992,  0.01110129, -0.02978406, ..., -0.01409856,\n",
       "         -0.00653744, -0.01702018],\n",
       "        ...,\n",
       "        [ 0.15417409,  0.02183502, -0.13483599, ..., -0.03213798,\n",
       "          0.08678889, -0.08537907],\n",
       "        [ 0.17847452,  0.08058877, -0.15529509, ..., -0.13777556,\n",
       "          0.06250089, -0.09210343],\n",
       "        [ 0.02077168,  0.08728888, -0.08879454, ..., -0.09695212,\n",
       "          0.1407871 , -0.09895734]], dtype=float32),\n",
       " array([[-0.3248671 ,  2.5016818 , -1.7128868 , -2.1903372 ,  2.206936  ,\n",
       "          1.846447  , -2.295708  ,  2.6319044 , -1.4894768 ,  1.9458405 ,\n",
       "         -2.5153909 , -2.2002606 , -2.3559897 , -0.10990733, -1.7354534 ,\n",
       "          1.9327366 ],\n",
       "        [-0.31096733,  2.346235  , -1.7330129 , -1.6590712 ,  2.4341052 ,\n",
       "          2.4364088 , -2.0215805 ,  2.2765753 , -2.176301  ,  2.6559143 ,\n",
       "         -1.7926877 , -2.1566217 , -1.9493102 , -0.33547482, -2.056711  ,\n",
       "          1.7443838 ],\n",
       "        [-0.30401653, -2.2039144 ,  2.3753295 ,  1.1820337 , -2.103163  ,\n",
       "         -2.1437802 ,  1.5631834 , -2.040498  ,  1.2528459 , -2.438447  ,\n",
       "          2.0810962 ,  1.745272  ,  2.0668833 , -0.08843784,  1.0814738 ,\n",
       "         -1.6275052 ],\n",
       "        [-0.04552492, -2.1338756 ,  1.6865765 ,  2.0443552 , -2.228939  ,\n",
       "         -2.5734582 ,  1.6214126 , -1.9845953 ,  1.8976245 , -2.0785568 ,\n",
       "          2.2792485 ,  2.012981  ,  1.8632138 , -0.01687781,  2.1198897 ,\n",
       "         -2.2616029 ],\n",
       "        [-0.10182795, -0.04333776,  0.5112156 ,  0.8271092 , -0.22847387,\n",
       "          0.10425723,  0.2450022 , -0.30115318,  0.31286147,  0.19416681,\n",
       "          1.1479893 ,  1.0439769 ,  0.7561949 ,  0.00295047,  0.9771006 ,\n",
       "         -0.03281122],\n",
       "        [-0.02015697, -2.465483  ,  2.4203024 ,  1.5580381 , -1.9209841 ,\n",
       "         -1.8143692 ,  1.8079307 , -1.759681  ,  1.9022335 , -2.644707  ,\n",
       "          1.963739  ,  2.2723477 ,  1.6308556 , -0.37764406,  1.9417691 ,\n",
       "         -2.1764386 ],\n",
       "        [-0.17176871,  2.1638317 , -2.5577726 , -1.986324  ,  2.8046694 ,\n",
       "          1.6579665 , -2.2815573 ,  2.700563  , -2.1278481 ,  1.8789467 ,\n",
       "         -1.6854388 , -1.9803699 , -2.2914565 , -0.41054875, -2.097258  ,\n",
       "          2.3519926 ],\n",
       "        [-0.03204036, -2.200146  ,  2.286137  ,  1.9727263 , -2.47167   ,\n",
       "         -2.3818748 ,  2.000565  , -2.4944203 ,  2.3328264 , -2.7236702 ,\n",
       "          2.029828  ,  2.1615071 ,  1.7179594 , -0.25263512,  1.9327865 ,\n",
       "         -2.4705522 ]], dtype=float32),\n",
       " array([-0.05068362,  0.09542343,  0.11412311,  0.09119558,  0.11677708,\n",
       "         0.07730448,  0.09566631,  0.10515373,  0.09946275,  0.11485814,\n",
       "         0.1022846 ,  0.10681779,  0.10100517, -0.04809421,  0.09049098,\n",
       "         0.0825884 ], dtype=float32),\n",
       " array([[ 0.03283356],\n",
       "        [ 2.010824  ],\n",
       "        [-1.4801607 ],\n",
       "        [-2.0318289 ],\n",
       "        [ 1.8613652 ],\n",
       "        [ 2.1328197 ],\n",
       "        [-1.7822653 ],\n",
       "        [ 1.9040508 ],\n",
       "        [-1.9784209 ],\n",
       "        [ 1.8558873 ],\n",
       "        [-1.6666694 ],\n",
       "        [-1.8475479 ],\n",
       "        [-1.6852915 ],\n",
       "        [ 0.10363483],\n",
       "        [-1.9769493 ],\n",
       "        [ 2.2226317 ]], dtype=float32),\n",
       " array([0.15717383], dtype=float32)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_36 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m80,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,485</span> (939.40 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m240,485\u001b[0m (939.40 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,161</span> (313.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m80,161\u001b[0m (313.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160,324</span> (626.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m160,324\u001b[0m (626.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_layer(\"embedding_36\").get_weights()[0]\n",
    "vocab = vectorized_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
